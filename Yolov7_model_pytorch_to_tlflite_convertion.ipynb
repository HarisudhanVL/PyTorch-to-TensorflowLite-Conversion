{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EHaT96ByTKlYZEeaNRd4aRp3BsmqkkB-",
      "authorship_tag": "ABX9TyOeKoNy1ljX5obT95di8aEi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarisudhanVL/PyTorch-to-TensorflowLite-Conversion/blob/main/Yolov7_model_pytorch_to_tlflite_convertion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCMVSOS53rKZ",
        "outputId": "27508292-620a-4f58-a1a2-b9634d2a694c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.1 MB 16.2 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.5 MB 68.0 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0 MB 55.5 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46 kB 2.6 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 237 kB 58.4 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86 kB 5.5 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51 kB 6.8 MB/s \n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx-tf\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 226 kB 15.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 72.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from onnx-tf) (6.0)\n",
            "Requirement already satisfied: onnx>=1.10.2 in /usr/local/lib/python3.7/dist-packages (from onnx-tf) (1.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.10.2->onnx-tf) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.10.2->onnx-tf) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.10.2->onnx-tf) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.12.2->onnx>=1.10.2->onnx-tf) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->onnx-tf) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->onnx-tf) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons->onnx-tf) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons, onnx-tf\n",
            "Successfully installed onnx-tf-1.10.0 tensorflow-addons-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip --quiet install onnx onnxruntime onnxsim\n",
        "!pip install onnx-tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *!pip --quiet install onnx onnxruntime onnxsim*\n",
        "\n",
        "The above commands installs the **ONNX (Open Neural Network Excahnge)**, its runtime and ONNX simplification.\n",
        "\n",
        "**onnxruntime** is a high-performance runtime for executing ONNX models across various platforms and devices.\n",
        "\n",
        "**onnxsim** is a tool that simplifies and optimizes ONNX models by removing unnecessary operations and simplifying their structure.\n",
        "\n",
        "## *!pip install onnx-tf*\n",
        "\n",
        "This command installs the onnx-tf package, which is a library that enables conversion between ONNX and TensorFlow formats."
      ],
      "metadata": {
        "id": "K4EYphkGYEnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Clone the YOLOv7 model from the github repo** **and download the yolov7.pt pytorch file from the specified URL**"
      ],
      "metadata": {
        "id": "WbbH32ASZdLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git\n",
        "%cd yolov7\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EQ174s-CLxW",
        "outputId": "ecdb355c-dcd6-45d9-c840-bf9942a64554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 998, done.\u001b[K\n",
            "remote: Total 998 (delta 0), reused 0 (delta 0), pack-reused 998\u001b[K\n",
            "Receiving objects: 100% (998/998), 69.77 MiB | 25.72 MiB/s, done.\n",
            "Resolving deltas: 100% (466/466), done.\n",
            "/content/yolov7\n",
            "--2022-10-28 05:35:40--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221028%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221028T053540Z&X-Amz-Expires=300&X-Amz-Signature=6d9a2bb0fd5e0cff2f21c098ff2147fa5a0e865e9fbf01c34c33355b32bed1a9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-10-28 05:35:40--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221028%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221028T053540Z&X-Amz-Expires=300&X-Amz-Signature=6d9a2bb0fd5e0cff2f21c098ff2147fa5a0e865e9fbf01c34c33355b32bed1a9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75587165 (72M) [application/octet-stream]\n",
            "Saving to: â€˜yolov7.ptâ€™\n",
            "\n",
            "yolov7.pt           100%[===================>]  72.08M  20.7MB/s    in 3.8s    \n",
            "\n",
            "2022-10-28 05:35:44 (19.0 MB/s) - â€˜yolov7.ptâ€™ saved [75587165/75587165]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Command line instruction to run the python script file.**\n",
        "### The PyTorch file is converted into ONNX format."
      ],
      "metadata": {
        "id": "7CSnwk7zYlW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov7/export.py --weights /content/yolov7-final.pt --grid --end2end --simplify \\\n",
        "--topk-all 100 --iou-thres 0.65 --conf-thres 0.35 --img-size 640 640 --max-wh 640"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg9bf81eFsBl",
        "outputId": "6ae53fd5-0099-46df-a9c5-834c0f50a1a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Import onnx_graphsurgeon failure: No module named 'onnx_graphsurgeon'\n",
            "Namespace(batch_size=1, conf_thres=0.35, device='cpu', dynamic=False, dynamic_batch=False, end2end=True, fp16=False, grid=True, img_size=[640, 640], include_nms=False, int8=False, iou_thres=0.65, max_wh=640, simplify=True, topk_all=100, weights='/content/yolov7-final.pt')\n",
            "YOLOR ðŸš€ v0.1-115-g072f76c torch 1.12.1+cu113 CPU\n",
            "\n",
            "Fusing layers... \n",
            "IDetect.fuse\n",
            "Model Summary: 208 layers, 6010302 parameters, 0 gradients\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\n",
            "Starting TorchScript export with torch 1.12.1+cu113...\n",
            "/content/yolov7/models/yolo.py:150: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
            "TorchScript export success, saved as /content/yolov7-final.torchscript.pt\n",
            "CoreML export failure: No module named 'coremltools'\n",
            "\n",
            "Starting TorchScript-Lite export with torch 1.12.1+cu113...\n",
            "TorchScript-Lite export success, saved as /content/yolov7-final.torchscript.ptl\n",
            "\n",
            "Starting ONNX export with onnx 1.12.0...\n",
            "onnxruntime\n",
            "/content/yolov7/models/experimental.py:99: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  batches = torch.randint(0, batch, (num_det,)).sort()[0].to(device)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/symbolic_opset9.py:4194: UserWarning: Exporting aten::index operator of advanced indexing in opset 12 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
            "  + \"If indices include negative values, the exported graph will produce incorrect results.\"\n",
            "\n",
            "Starting to simplify ONNX...\n",
            "ONNX export success, saved as /content/yolov7-final.onnx\n",
            "\n",
            "Export complete (11.05s). Visualize with https://github.com/lutzroeder/netron.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Convertion of OONX format to TensorFlow format.**"
      ],
      "metadata": {
        "id": "l7FYNGs0Z7Ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!onnx-tf convert -i /content/yolov7-final.onnx -o /content/yolov7-final.pb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcbmNSmBF_fD",
        "outputId": "63a1edf8-8c62-4b8f-99ac-7baef03a7e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-28 05:41:15,886 - onnx-tf - INFO - Start converting onnx pb to tf saved model\n",
            "INFO:onnx-tf:Start converting onnx pb to tf saved model\n",
            "2022-10-28 05:41:15.976746: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "2022-10-28 05:41:30,890 - onnx-tf - INFO - Converting completes successfully.\n",
            "INFO:onnx-tf:Converting completes successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Convertion of Tensorflow format to TensorFlowlite format**"
      ],
      "metadata": {
        "id": "MFqgEmspakga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/yolov7-final.pb')\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('/content/yolov7_model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "y2anuXx5GjgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Successfully the PyTorch file (.pt) was converted into TensorFlowLite (.tflite).**"
      ],
      "metadata": {
        "id": "vwiCbLJWbCYJ"
      }
    }
  ]
}